model = "gpt-5.3-codex"
model_reasoning_effort = "high"
tool_output_token_limit = 25000
# Leave room for native compaction near the 272â€“273k context window.
model_auto_compact_token_limit = 233000
[features]
# Use PTY-backed execution instead of pipes - programs think they're in a real terminal,
# enabling colors, progress bars, and proper handling of interactive tools like test runners
unified_exec = true
apply_patch_freeform = true
web_search_request = true
skills = true
shell_snapshot = true

[mcp_servers.context7]
command = "npx"
args = ["-y", "@upstash/context7-mcp"]
